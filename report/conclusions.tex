\chapter{Conclusion and Future work \label{chap:conclusion}}
This chapter concludes the project and provides suggestions as to how the project can be potentially improved upon in the future.

\section{Conclusion}
This project has developed software capable of creating relatively natural-looking animated dialogue scenes using nothing but a script (resembling a film script) as input. While the gestures and motions are often `correct' they are often overdone, reducing the overall realism of the scene. Despite that, the generated scenes were often found more enjoyable by the audience than the dialogue scenes found in modern games.

The main problems that the software faces are sarcasm and ambiguity. There exists a possibility that these issues cannot be solved by natural language processing alone and other methods should be employed to solve these issues.

The developed software requires far less manual preparation and work than other existing systems. The trade-off between realism (and quality) and the amount of required work makes the system viable for: studios which can't afford to develop their own animation generation system or hire of additional animators, amateur and indie developers who either lack skill or time to produce large quantities of animation, and prototyping - the swift execution of the program allows for a quick assembly of a scene which can be then looked at and improved upon.

The project, especially upon further development, has potential to bring cheap and relatively good animation to the industry. However, big studios will would probably remain uninterested in this approach, as they already have developed their in-house solutions to the problem of animation generation and have far more resources available.

\section{Potential use outside of games}
The software was developed primarily for use in games, however, there are also other areas that would benefit from a similar system. One of such areas is robotics, which suffers from a very similar problem to games. Robots, when interacting with people, must behave in a human-like manner with proper gestures and body language. Matching emotions with the motion capture database is something that could be a potential solution - only instead of creating an animation, the movements could be re-enacted by a robot. It has been established that robots which clearly indicate their intentions with body language are perceived as much more pleasant and easy to interact with.~\cite{mutlurobots}


\section{Future work}
While the software managed to deliver on its most important requirements, there is a lot of room for improvements. Most importantly, this project focused mostly on how the animations are assembled from the database with the use of emotion analysis. The generation itself was not a priority as there exist a lot of systems that do this, so there was nothing to be learned here. However, for this project to become commercially viable, the generation of animations should be improved. Potential improvements include: more complex camera movement, inclusion of more characters in the scene, blending the motions so that switching from one gesture to another looks more natural, creating the scene immediately with background objects (possibly also described with the script), etc.

The hardest problem this software has yet to overcome is sarcasm and ambiguity. The emotions and body language of a person are not only and fully dependent and what they say - it is also important how they say it and when, what is the context and setting of the scene and more. I believe that this software could become a part of a bigger emotion-to-dialogue-animation tool, which features other approaches to solve the problem. Potential extensions to the software are:
\begin{itemize}
	\item Usage of machine learning to analyse emotions from audio (if audio is available before scene generation).
	\item Usage of machine learning to analyse emotions from facial movements (the voice actors' faces could potentially be recorded while reciting they are reading script).
	\item Using NLP to also analyse past interactions between characters (and build a profile for each character and their relations with others) and taking into account not only the emotions of the person currently speaking but of all characters within the scene.
\end{itemize}