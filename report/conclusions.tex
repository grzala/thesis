\chapter{Conclusion and Future work \label{chap:conclusion}}
This chapter concludes the project and provides suggestions as to how the project can be potentially improved upon in the future.

\section{Conclusion}
This project has developed software capable of creating natural-looking animated dialogue scenes using nothing but a script (resembling a film script) as input. The scenes generated by the software are more expressive than scenes featured in games, with body language matching the emotions conveyed through speech. While the gestures and motions are often `correct' they are often overdone reducing the overall realism o the scene. Despite that, the generated scenes were often found more enjoyable than those of modern games by the audience.

The main problems that the software faces are sarcasm and ambiguity. There exists a possibility that these issues cannot be solved by natural language processing alone and other methods should be employed to solve these issues.

The developed software requires far less manual preparation and work than other existing systems. The trade-off between realism (and quality) and the amount of required work makes the system viable for: studios which can't afford to develop their own animation generation system or hire of additional animators, amateur and indie developers who either lack skill or time to produce large quantities of animation and prototyping - the quick execution of the program allows for a quick assembly of a scene which can be then looked at and improved upon.

The project, especially upon further development, has potential to bring cheap and relatively good animation to games that were unable to do so. However, big studios will would probably remain uninterested in this approach as they already have developed their in-house solutions to the problem of animation generation and have far more resources available.

\section{Potential use outside of games}
The software was developed primarily for use in games, however there are also other areas that would benefit from a similar system. 


\section{Future work}
While the software managed to deliver on its most important requirements, there is a lot of room for improvements. Most importantly, this project focused mostly on how the animations are assembled from the database with use of emotion analysis. The generation itself was not itself a priority as there exist a lot of system that do this part, so there was nothing to be learned here. However, for this project to become commercially viable, the generation of animations could be improved. Potential improvements include: more complex camera movement, inclusion of more characters in the scene, blending the motions so that switching from one gesture to another looks more natural, creating the scene immediately with background objects (possibly also described with the script), etc.

The hardest problem this software has yet to overcome is sarcasm and ambiguity. The emotions and body language of a person are not only and fully dependent and what they say - it is also important how they say it and when, what is the context and setting of the scene and more. I believe that this software could become a part of a bigger emotion-to-dialogue-animation tool, which features other approaches to solve the problem. Potential extensions to the software:
\begin{itemize}
	\item Usage of machine learning to analyse emotions from audio (if audio is available before scene generation).
	\item Usage of machine learning to analyse emotions from facial movements (the voice actors' faces could potentially be recorded while reciting the script).
	\item Using NLP to also analyse past interactions between characters (and build a profile for each character and their relations with others) and taking into account not only the emotions of the person currently speaking but of all characters within the scene.
\end{itemize}